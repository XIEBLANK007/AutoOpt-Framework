{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7CCPkk9yXUR"
      },
      "outputs": [],
      "source": [
        "# %% [code] Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjzeXWIhyVGg"
      },
      "outputs": [],
      "source": [
        "# %% [code] Environment Setup\n",
        "!pip install transformers accelerate datasets peft --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnq2KyEXylQn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/PYOMO')  # Change path as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8-860bZ7mDT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWGp1s5Y7jbx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"  # change this if necessary\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model_teacher = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "model_teacher.eval()\n",
        "\n",
        "print(\"Teacher model loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9LlwLbYTuS2"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets\n",
        "!pip install fsspec==2023.9.2\n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDVMiHKKXZXT"
      },
      "outputs": [],
      "source": [
        "# TO extract samples having both latex and pyomo in the jsonl file.\n",
        "import json\n",
        "\n",
        "# === Input and output paths ===\n",
        "input_file = \"/content/drive/MyDrive/Combined/data.jsonl\"      # Your input JSON file\n",
        "output_file = \"/content/drive/MyDrive/filtered.json\"     # Output JSON file\n",
        "\n",
        "# === Load original JSON lines ===\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "# === Filter and transform ===\n",
        "converted_data = []\n",
        "for entry in data:\n",
        "    latex = entry.get(\"latex\", \"\").strip()\n",
        "    pyomo = entry.get(\"pyomo\", \"\").strip()\n",
        "    if latex and pyomo:  # Include only if pyomo is not blank\n",
        "        converted_data.append({\"input\": latex, \"output\": pyomo})\n",
        "\n",
        "# === Save to new JSON lines file ===\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for item in converted_data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Filtered {len(converted_data)} valid entries saved to '{output_file}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb35oVfOMvNZ"
      },
      "outputs": [],
      "source": [
        "#Splitting the dataset json to training and test splits.\n",
        "\n",
        "import json\n",
        "import random\n",
        "\n",
        "# === Input and output paths ===\n",
        "input_file = \"/content/drive/MyDrive/PYOMO/filtered.json\"        # File created from previous step\n",
        "train_file = \"/content/drive/MyDrive/PYOMO/filtered_train.jsonl\"\n",
        "test_file = \"/content/drive/MyDrive/PYOMO/filtered_test.jsonl\"\n",
        "\n",
        "# === Parameters ===\n",
        "test_ratio = 0.2                    # 20% for test, 80% for train\n",
        "random_seed = 42                   # For reproducibility\n",
        "\n",
        "# === Load data ===\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "# === Shuffle and split ===\n",
        "random.seed(random_seed)\n",
        "random.shuffle(data)\n",
        "\n",
        "split_index = int(len(data) * (1 - test_ratio))\n",
        "train_data = data[:split_index]\n",
        "test_data = data[split_index:]\n",
        "\n",
        "# === Write outputs ===\n",
        "with open(train_file, \"w\", encoding=\"utf-8\") as f_train:\n",
        "    for item in train_data:\n",
        "        f_train.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "with open(test_file, \"w\", encoding=\"utf-8\") as f_test:\n",
        "    for item in test_data:\n",
        "        f_test.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Total: {len(data)} → Train: {len(train_data)}, Test: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAtKMNMvAw7L"
      },
      "outputs": [],
      "source": [
        "# ADDING \"endoftext\" token at the end of each pyomo script in train split.\n",
        "\n",
        "import json\n",
        "\n",
        "# Paths\n",
        "input_path = \"/content/drive/MyDrive/PYOMO/filtered_train.json\"\n",
        "output_path = \"/content/drive/MyDrive/PYOMO/filtered_with_endtoken.jsonl\"\n",
        "\n",
        "# Process and write\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as infile, open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    for line in infile:\n",
        "        data = json.loads(line)\n",
        "        # Append end token to output\n",
        "        if not data[\"output\"].strip().endswith(\"<|endoftext|>\"):\n",
        "            data[\"output\"] += \"<|endoftext|>\"\n",
        "        # Write back to new file\n",
        "        json.dump(data, outfile, ensure_ascii=False)\n",
        "        outfile.write(\"\\n\")\n",
        "\n",
        "print(f\"✅ Finished! New dataset saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vd07HEFMnv9"
      },
      "outputs": [],
      "source": [
        "# Finetuning on our json file having latex as \"input\" and pyomo as \"output\"\n",
        "\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ✅ Load dataset\n",
        "dataset_path = \"/content/drive/MyDrive/PYOMO/filtered_with_endtoken.jsonl\"\n",
        "raw_dataset = load_dataset(\"json\", data_files=dataset_path)\n",
        "\n",
        "# ✅ Add special tokens\n",
        "special_tokens = {'eos_token': '<|endoftext|>'}\n",
        "tokenizer.add_special_tokens(special_tokens)\n",
        "model_teacher.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# ✅ Preprocessing function (with consistent instruct prompt)\n",
        "def preprocess_function(examples):\n",
        "    texts = [f\"Convert the following LaTeX problem into clean Pyomo code. Output only variable declarations, objective function, and constraint.\\nLaTeX Problem:\\n{inp}\\n### Solution:\\n{outp}\" for inp, outp in zip(examples[\"input\"], examples[\"output\"])]\n",
        "    return tokenizer(texts, truncation=True, padding=\"max_length\", max_length=1024)\n",
        "\n",
        "tokenized_dataset = raw_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# ✅ Data collator for causal LM\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "# ✅ Training arguments optimized for Colab\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/PYOMO/finetuned_student\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=20,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=5e-5,\n",
        "    logging_steps=20,\n",
        "    save_steps=200,  # less frequent saves\n",
        "    save_total_limit=1,  # only latest checkpoint to save space\n",
        "    fp16=True,\n",
        "    resume_from_checkpoint=True,\n",
        "    report_to=[],\n",
        ")\n",
        "\n",
        "# ✅ Trainer\n",
        "trainer = Trainer(\n",
        "    model=model_teacher,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# ✅ Start training\n",
        "trainer.train()\n",
        "\n",
        "# ✅ Save final model and tokenizer\n",
        "trainer.save_model(\"/content/drive/MyDrive/PYOMO/finetuned_student\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/PYOMO/finetuned_student\")\n",
        "\n",
        "print(\"✅ Finetuning complete. Finetuned student model saved in Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgyS4pmTAwOE"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "\n",
        "import re\n",
        "import json\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.metrics import edit_distance\n",
        "import jiwer\n",
        "\n",
        "# === CONFIG ===\n",
        "MODEL_PATH = \"/content/drive/MyDrive/PYOMO/finetuned_student\"              # path to model weights\n",
        "TEST_JSON_PATH = \"/content/drive/MyDrive/PYOMO/filtered_test.jsonl\"      # input=latex, output=pyomo\n",
        "OUTPUT_TXT_PATH = \"/content/drive/MyDrive/PYOMO/TEMP_evaluation_report.txt\"\n",
        "MAX_NEW_TOKENS = 512\n",
        "\n",
        "# === Setup model + tokenizer ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH).to(device)\n",
        "model.eval()\n",
        "\n",
        "# Add special token if missing\n",
        "tokenizer.add_special_tokens({'eos_token': '<|endoftext|>'})\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# === Tokenization Helpers ===\n",
        "def tokenize_latex(expr):\n",
        "    return re.findall(r'(\\\\[a-zA-Z]+|[{}_^=+\\-*/(),]|[a-zA-Z]+|\\d+)', expr)\n",
        "\n",
        "class TokenizeTransform(jiwer.transforms.AbstractTransform):\n",
        "    def process_string(self, s: str):\n",
        "        return tokenize_latex(s)\n",
        "    def process_list(self, tokens: list[str]):\n",
        "        return [self.process_string(token) for token in tokens]\n",
        "\n",
        "# === Metric Computation ===\n",
        "def compute_cer(pairs):\n",
        "    gt_list, pred_list = [], []\n",
        "    for gt, pred in pairs:\n",
        "        gt = str(gt).strip().replace(\"\\n\", \" \")\n",
        "        pred = str(pred).strip().replace(\"\\n\", \" \")\n",
        "        if gt == \"\" and pred == \"\":\n",
        "            continue\n",
        "        gt_list.append(gt)\n",
        "        pred_list.append(pred)\n",
        "    if not gt_list:\n",
        "        return 1.0\n",
        "    return jiwer.cer(\n",
        "        truth=gt_list,\n",
        "        hypothesis=pred_list,\n",
        "        reference_transform=TokenizeTransform(),\n",
        "        hypothesis_transform=TokenizeTransform()\n",
        "    )\n",
        "\n",
        "def compute_metrics(pairs):\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    bleus = []\n",
        "    for gt, pred in pairs:\n",
        "        gt = gt.strip().replace(\"\\n\", \" \")\n",
        "        pred = pred.strip().replace(\"\\n\", \" \")\n",
        "        bleu = sentence_bleu([tokenize_latex(gt)], tokenize_latex(pred), smoothing_function=smoothie)\n",
        "        bleus.append(bleu)\n",
        "    cer = compute_cer(pairs)\n",
        "    return {\n",
        "        \"bleu\": sum(bleus) / len(bleus),\n",
        "        \"cer\": cer\n",
        "    }\n",
        "\n",
        "def generate_pyomo_code(latex_input):\n",
        "    prompt = f\"Convert the following LaTeX problem into clean Pyomo code. Output only variable declarations, objective function, and constraint.\\nLaTeX Problem:\\n{latex_input}\\n### Solution:\\n\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Let model continue from the END of the prompt\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_new_tokens=512,\n",
        "            do_sample=False,\n",
        "            num_beams=1,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Strip the original prompt if needed\n",
        "    if full_text.startswith(prompt):\n",
        "        generated = full_text[len(prompt):].strip()\n",
        "    else:\n",
        "        # Fallback: split by \"### Solution:\"\n",
        "        generated = full_text.split(\"### Solution:\")[-1].strip()\n",
        "\n",
        "    return generated.replace('\\n', ' ')\n",
        "\n",
        "# === Evaluation Loop ===\n",
        "def run_inference_evaluation():\n",
        "    with open(TEST_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        examples = [json.loads(line) for line in f if \"input\" in line and \"output\" in line]\n",
        "\n",
        "    if not examples:\n",
        "        print(\"❌ No valid examples found in the test file.\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "\n",
        "    with open(OUTPUT_TXT_PATH, \"w\", encoding=\"utf-8\") as fout:\n",
        "        for i, ex in enumerate(tqdm(examples, desc=\"Evaluating\")):\n",
        "            latex = ex[\"input\"].strip()\n",
        "            gt_pyomo = ex[\"output\"].strip()\n",
        "\n",
        "            try:\n",
        "                pred_pyomo = generate_pyomo_code(latex)\n",
        "            except Exception as e:\n",
        "                print(f\"[Error on Sample {i+1}] {e}\")\n",
        "                pred_pyomo = \"\"\n",
        "\n",
        "            bleu = sentence_bleu([tokenize_latex(gt_pyomo)], tokenize_latex(pred_pyomo), smoothing_function=SmoothingFunction().method4)\n",
        "            ed = edit_distance(pred_pyomo, gt_pyomo) / max(len(pred_pyomo), len(gt_pyomo)) if max(len(pred_pyomo), len(gt_pyomo)) > 0 else 0.0\n",
        "\n",
        "            results.append((gt_pyomo, pred_pyomo))\n",
        "\n",
        "            fout.write(f\"Sample {i+1}\\n\")\n",
        "            fout.write(f\"Input (LaTeX)   : {latex}\\n\")\n",
        "            fout.write(f\"Ground Truth    : {gt_pyomo}\\n\")\n",
        "            fout.write(f\"Prediction      : {pred_pyomo}\\n\")\n",
        "            fout.write(f\"BLEU            : {bleu:.4f}\\n\")\n",
        "            fout.write(\"-\" * 60 + \"\\n\")\n",
        "\n",
        "        # Final summary\n",
        "        metrics = compute_metrics(results)\n",
        "        fout.write(\"\\n=== Summary ===\\n\")\n",
        "        fout.write(f\"Total Samples    : {len(results)}\\n\")\n",
        "        fout.write(f\"Average BLEU     : {metrics['bleu']:.4f}\\n\")\n",
        "        fout.write(f\"Average CER      : {metrics['cer']:.4f}\\n\")\n",
        "\n",
        "    print(\"\\n✅ Inference and Evaluation complete.\")\n",
        "    print(f\"Report saved to: {OUTPUT_TXT_PATH}\")\n",
        "\n",
        "# === Run It ===\n",
        "run_inference_evaluation()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}